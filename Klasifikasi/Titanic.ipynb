{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import Feature Engineering/Preprocessing Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Import models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Import cross val and tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# import warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df_ori = pd.read_csv('https://raw.githubusercontent.com/FTDS-learning-materials/phase-1/master/w1/P1W1D3AM%20-%20Feature%20Engineering%20-%20Part%201%20-%20Titanic.csv')\n",
    "\n",
    "# Copy data ori\n",
    "df = df_ori.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check dataset 1\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statement >>> misal ada missing value, mari lihat jumlah dan persentasenya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "PassengerId     0.00\n",
      "Survived        0.00\n",
      "Pclass          0.00\n",
      "Name            0.00\n",
      "Sex             0.00\n",
      "Age            19.87\n",
      "SibSp           0.00\n",
      "Parch           0.00\n",
      "Ticket          0.00\n",
      "Fare            0.00\n",
      "Cabin          77.10\n",
      "Embarked        0.22\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(f'{round(df.isnull().mean()*100,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "karena kebutuhan kita skrg untuk belajar, jadi seluruh misval didrop saja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n",
      "PassengerId    0.0\n",
      "Survived       0.0\n",
      "Pclass         0.0\n",
      "Name           0.0\n",
      "Sex            0.0\n",
      "Age            0.0\n",
      "SibSp          0.0\n",
      "Parch          0.0\n",
      "Ticket         0.0\n",
      "Fare           0.0\n",
      "Cabin          0.0\n",
      "Embarked       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check after drop\n",
    "print(df.isnull().sum())\n",
    "print(f'{round(df.isnull().mean()*100,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check data duplicate\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split num cat col\n",
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df.Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>718</td>\n",
       "      <td>2</td>\n",
       "      <td>Troutt, Miss. Edwina Celia \"Winnie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34218</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>E101</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>Harrison, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112059</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>B94</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>711</td>\n",
       "      <td>1</td>\n",
       "      <td>Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17482</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>C90</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenfield, Mr. William Bertram</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PC 17759</td>\n",
       "      <td>63.3583</td>\n",
       "      <td>D10 D12</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>Hays, Miss. Margaret Bechstein</td>\n",
       "      <td>female</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C54</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                              Name  \\\n",
       "717          718       2               Troutt, Miss. Edwina Celia \"Winnie\"   \n",
       "263          264       1                             Harrison, Mr. William   \n",
       "710          711       1  Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")   \n",
       "97            98       1                   Greenfield, Mr. William Bertram   \n",
       "310          311       1                    Hays, Miss. Margaret Bechstein   \n",
       "\n",
       "        Sex   Age  SibSp  Parch    Ticket     Fare    Cabin Embarked  \n",
       "717  female  27.0      0      0     34218  10.5000     E101        S  \n",
       "263    male  40.0      0      0    112059   0.0000      B94        S  \n",
       "710  female  24.0      0      0  PC 17482  49.5042      C90        C  \n",
       "97     male  23.0      0      1  PC 17759  63.3583  D10 D12        C  \n",
       "310  female  24.0      0      0     11767  83.1583      C54        C  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=70)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saya berasumsi passenger id, name, dan ticket itu korelasi dengan targetnya rendah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked'], dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection\n",
    "X_train.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "X_test.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical :['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "categorical:['Sex', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Split num and cat col\n",
    "num_col = X_train.select_dtypes(exclude=['object']).columns.tolist()\n",
    "cat_col = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f'numerical :{num_col}')\n",
    "print(f'categorical:{cat_col}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah berhasil memisahkan categorical dan numerical column, sekarang saya akan melakukan scaling menggunakan `StandardScaler()` karena .... . Lalu mengencode dengan `OneHotEncoder()` karena .... . Setelah itu dimasukkan ke dalam variable preprocess untuk dilakukan transformasi menggunakan `ColumnTransformer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling and encoding in column transformer\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', scaler,num_col),\n",
    "        ('categorical', encoder,cat_col)\n",
    "        ], \n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using pipeline\n",
    "pipe_log = make_pipeline(preprocess,LogisticRegression())\n",
    "pipe_svc = make_pipeline(preprocess,SVC())\n",
    "pipe_knn = make_pipeline(preprocess,KNeighborsClassifier())\n",
    "pipe_nb = make_pipeline(preprocess,GaussianNB())\n",
    "pipe_dt = make_pipeline(preprocess,DecisionTreeClassifier(random_state=70))\n",
    "pipe_rf = make_pipeline(preprocess,RandomForestClassifier(random_state=70))\n",
    "pipe_ada = make_pipeline(preprocess,AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross val for each pipeline\n",
    "cv_log = cross_val_score(pipe_log, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_svc = cross_val_score(pipe_svc, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_knn = cross_val_score(pipe_knn, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_nb = cross_val_score(pipe_nb, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_dt = cross_val_score(pipe_dt, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_rf = cross_val_score(pipe_rf, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)\n",
    "cv_ada = cross_val_score(pipe_ada, X_train, y_train, cv = 5, scoring='f1', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log\n",
      "f1-score - All - Cross Validation : [0.76190476 0.87179487 0.92682927 0.75675676 0.76923077]\n",
      "f1-score - Mean - Cross Validation : 0.8173032855959684\n",
      "f1-score - Std - Cross Validation : 0.06929807971867405\n",
      "f1-score - Range of test set : 0.7480052058772944 - 0.8866013653146425\n",
      "--------------------------------------------------\n",
      "svc\n",
      "f1-score - All - Cross Validation : [0.79069767 0.86486486 0.8372093  0.66666667 0.76923077]\n",
      "f1-score - Mean - Cross Validation : 0.7857338555012973\n",
      "f1-score - Std - Cross Validation : 0.06838921710377244\n",
      "f1-score - Range of test set : 0.7173446383975248 - 0.8541230726050697\n",
      "--------------------------------------------------\n",
      "knn\n",
      "f1-score - All - Cross Validation : [0.77272727 0.85714286 0.7804878  0.73684211 0.73684211]\n",
      "f1-score - Mean - Cross Validation : 0.7768084290548989\n",
      "f1-score - Std - Cross Validation : 0.04399642725151764\n",
      "f1-score - Range of test set : 0.7328120018033812 - 0.8208048563064165\n",
      "--------------------------------------------------\n",
      "nb\n",
      "f1-score - All - Cross Validation : [0.37037037 0.46153846 0.17391304 0.37037037 0.4516129 ]\n",
      "f1-score - Mean - Cross Validation : 0.36556102979665395\n",
      "f1-score - Std - Cross Validation : 0.10333615291641467\n",
      "f1-score - Range of test set : 0.26222487688023927 - 0.4688971827130686\n",
      "--------------------------------------------------\n",
      "dt\n",
      "f1-score - All - Cross Validation : [0.76190476 0.85       0.85714286 0.76923077 0.78947368]\n",
      "f1-score - Mean - Cross Validation : 0.805550414497783\n",
      "f1-score - Std - Cross Validation : 0.04029904879454543\n",
      "f1-score - Range of test set : 0.7652513657032376 - 0.8458494632923284\n",
      "--------------------------------------------------\n",
      "rf\n",
      "f1-score - All - Cross Validation : [0.75       0.92682927 0.92307692 0.7804878  0.82051282]\n",
      "f1-score - Mean - Cross Validation : 0.840181363352095\n",
      "f1-score - Std - Cross Validation : 0.07274941106214267\n",
      "f1-score - Range of test set : 0.7674319522899524 - 0.9129307744142376\n",
      "--------------------------------------------------\n",
      "ada\n",
      "f1-score - All - Cross Validation : [0.73170732 0.89473684 0.87179487 0.85       0.82051282]\n",
      "f1-score - Mean - Cross Validation : 0.8337503702972253\n",
      "f1-score - Std - Cross Validation : 0.05660176982896591\n",
      "f1-score - Range of test set : 0.7771486004682594 - 0.8903521401261912\n",
      "--------------------------------------------------\n",
      "Best Model: rf \n",
      "Cross Val Mean from best model: 0.840181363352095\n"
     ]
    }
   ],
   "source": [
    "# Finding best model based on Cross_val_score (mean)\n",
    "\n",
    "name_model = []\n",
    "cv_scores = 0\n",
    "for cv,name in zip([cv_log,cv_svc,cv_knn,cv_nb,cv_dt,cv_rf,cv_ada],\n",
    "                   ['log','svc','knn','nb','dt','rf','ada']):\n",
    "    \n",
    "    print(name)\n",
    "    print('f1-score - All - Cross Validation :', cv)\n",
    "    print('f1-score - Mean - Cross Validation :', cv.mean())\n",
    "    print('f1-score - Std - Cross Validation :', cv.std())\n",
    "    print('f1-score - Range of test set :', (cv.mean()-cv.std()), '-', (cv.mean()+cv.std()))\n",
    "    print('-'*50)\n",
    "    if cv.mean() > cv_scores:\n",
    "        cv_scores = cv.mean()\n",
    "        name_model = name\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "print(f'Best Model: {name_model}')\n",
    "print(f'Cross Val Mean from best model: {cv_scores}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
